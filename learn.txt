ovs:
gre
ovs-vsctl add-port br0 gre0 -- set interface gre0 type=gre options:local_ip=10.9.22.233 options:remote_ip=10.9.32.30 options:key=flow
ovs-vsctl add-port br0 vnet0
root@10-9-22-233:~# ovs-vsctl set bridge br0 protocols=OpenFlow13
root@10-9-22-233:~# ovs-ofctl add-flow br0 'in_port=2,actions=set_field:0x123456->tun_id,output:1' -O OpenFlow13
root@10-9-22-233:~# ovs-ofctl add-flow br0 in_port=1,tun_id=0x654321,actions=output:2  -O OpenFlow13

ovs-vsctl add-port br0 gre0 -- set interface gre0 type=gre options:local_ip=10.9.32.30 options:remote_ip=10.9.22.233 options:key=flow
ovs-vsctl add-port br0 vnet0
root@10-9-22-233:~# ovs-vsctl set bridge br0 protocols=OpenFlow13
root@10-9-22-233:~# ovs-ofctl add-flow br0 'in_port=2,actions=set_field:0x654321->tun_id,output:1' -O OpenFlow13
root@10-9-22-233:~# ovs-ofctl add-flow br0 in_port=1,tun_id=0x123456,actions=output:2  -O OpenFlow13

$ ovs-vsctl add-port br0 gre -- set Interface gre ofport_request=1 type=gre options:remote_ip=flow options:key=flow
$ ovs-ofctl add-flow br0 "in_port=LOCAL actions=set_tunnel:1,set_field:192.168.0.1->tun_dst,output:1"
$ ovs-ofctl add-flow br0 "in_port=1 tun_src=192.168.0.1 tun_id=1 actions=LOCAL"


ovs command
ovs-ofctl dump-flows br0 | grep -o -E 'priority.*' # -o outpu匹配额
ovs-vsctl list-ports br0 | grep -E  "veth.*" | xargs -i ovs-vsctl del-port br0 {}
# ovs-ofctl monitor br0 watch:
NXST_FLOW_MONITOR reply (xid=0x2):
 event=ADDED table=0 cookie=0 actions=NORMAL
NXST_FLOW_MONITOR reply (xid=0x0):
 event=DELETED reason=delete table=0 cookie=0 actions=NORMAL
NXST_FLOW_MONITOR reply (xid=0x0):
 event=ADDED table=0 cookie=0 actions=NORMAL
# ovs-ofctl snoop br0

vroute && dhcp
route: 52:53:00:0d:47:87
 cookie=0x0, duration=281.120s, table=0, n_packets=15, n_bytes=1449, priority=60000,in_port=1305,dl_src=52:53:00:0d:47:87,dl_dst=52:54:00:2b:d3:01 actions=set_field:0x4f1fa2->tun_id,output:168
 cookie=0x0, duration=278.692s, table=0, n_packets=14, n_bytes=1053, priority=60000,tun_id=0x4f1fa2,in_port=168,dl_src=52:54:00:2b:d3:01,dl_dst=52:53:00:0d:47:87 actions=output:1305
 cookie=0x0, duration=278.838s, table=0, n_packets=1, n_bytes=42, priority=60020,tun_id=0x4f1fa2,in_port=168,dl_src=52:54:00:2b:d3:01,dl_dst=ff:ff:ff:ff:ff:ff actions=output:1305
 cookie=0x0, duration=281.135s, table=0, n_packets=1, n_bytes=342, priority=60000,tun_id=0x4f1fa2,in_port=168,dl_src=52:54:00:2b:d3:01,dl_dst=ff:ff:ff:ff:ff:ff actions=output:1305


vm1: 52:54:00:2b:d3:01
cookie=0x0, duration=434.039s, table=0, n_packets=16, n_bytes=1185, priority=60000,in_port=1436,dl_src=52:54:00:2b:d3:01,dl_dst=52:53:00:0d:47:87 actions=set_field:0x4f1fa2->tun_id,output:260
 cookie=0x0, duration=434.091s, table=0, n_packets=1, n_bytes=42, priority=60020,in_port=1436,dl_src=52:54:00:2b:d3:01,dl_dst=ff:ff:ff:ff:ff:ff actions=set_field:0x4f1fa2->tun_id,output:220,output:260
 cookie=0x0, duration=436.371s, table=0, n_packets=1, n_bytes=342, priority=60000,in_port=1436,dl_src=52:54:00:2b:d3:01,dl_dst=ff:ff:ff:ff:ff:ff actions=set_field:0x4f1fa2->tun_id,output:220,output:260
 cookie=0x0, duration=436.251s, table=0, n_packets=16, n_bytes=1491, priority=60000,tun_id=0x4f1fa2,in_port=260,dl_src=52:53:00:0d:47:87,dl_dst=52:54:00:2b:d3:01 actions=output:1436

/////////////////////
tc filter add dev vnat1 parent ffff: protocol ip prio 40 estimator 500ms 1sec u32 match ip dst 192.168.0.0/24 police avrate 88mbit mtu 64k drop flowid ffff:

/////////////////////////////
install 
vim /usr/include/bits/typesizes.h 
#define __FD_SETSIZE            65535 
httperf --port 80 --server '120.132.49.47' --num-conn 40000000 --rate 10000



echo 1 > /proc/sys/net/ipv6/conf/all/disable_ipv6
cat /proc/sys/net/core/somaxconn
cat /sys/devices/system/cpu/cpu22/topology/core_id
cat /sys/devices/system/cpu/cpu22/topology/physical_package_id

//////////////////////////////////////
rpm

rpm -ivh xxx
rpm -iv --test xxx
rpm -iv --replacefiles
rpm -iv --replacepkgs
rpm -iv --nodeps --force

rpm -ev xxx
rpm -ev --test xxx
rpm -iv --nodeps

rpm -Uv xxx
rpm -Uv --test xxx
rpm -Uv --replacefiles
rpm -Uv --replacepkgs
rpm -Uv --nodeps --force

rpm -q xxx
rpm -qa
rpm -qf /bin/ls
rpm -qi xxx
rpm -qlp xxx

//////////////////////////////////////////
__LP64__ is not an abbreviation of "Leopard 64". It stands for "longs and pointers are 64 bits"

grub2-set-default 2
grub2-mkconfig -o /boot/grub2/grub.cfg



//////////////////////////

ovs-ofctl add-flow br0 "in_port=LOCAL,tcp,tcp_flags=+syn-ack,actions=learn(idle_timeout=60,table=1,dl_type=0x0800,nw_proto=6,NXM_OF_IP_SRC[]=NXM_OF_IP_DST[],NXM_OF_IP_DST[]=NXM_OF_IP_SRC[],NXM_OF_TCP_SRC[]=NXM_OF_TCP_DST[],NXM_OF_TCP_DST[]=NXM_OF_TCP_SRC[],output:NXM_OF_IN_PORT[]),set_tunnel:1,set_field:10.10.59.233->tun_dst,output:1"


[root@10-10-28-238 ~]# ovs-ofctl dump-flows br0
NXST_FLOW reply (xid=0x4):
 cookie=0x0, duration=9010.236s, table=0, n_packets=11, n_bytes=814, idle_age=1204,ip,tcp,in_port=LOCAL,tcp_flags=+syn-ack actions=learn(table=1,idle_timeout=60,eth_type=0x800,nw_proto=6,NXM_OF_IP_SRC[]=NXM_OF_IP_DST[],NXM_OF_IP_DST[]=NXM_OF_IP_SRC[],NXM_OF_TCP_SRC[]=NXM_OF_TCP_DST[],NXM_OF_TCP_DST[]=NXM_OF_TCP_SRC[],output:NXM_OF_IN_PORT[]),set_tunnel:0x1,load:0xa0a3be9->NXM_NX_TUN_IPV4_DST[],output:1
 cookie=0x0, duration=4255.119s, table=0, n_packets=6, n_bytes=287, idle_age=3232,ip,udp,in_port=LOCAL actions=learn(table=3,idle_timeout=60,eth_type=0x800,nw_proto=17,NXM_OF_IP_SRC[]=NXM_OF_IP_DST[],NXM_OF_IP_DST[]=NXM_OF_IP_SRC[],NXM_OF_UDP_SRC[]=NXM_OF_UDP_DST[],NXM_OF_UDP_DST[]=NXM_OF_UDP_SRC[],output:NXM_OF_IN_PORT[]),set_tunnel:0x1,load:0xa0a3be9->NXM_NX_TUN_IPV4_DST[],output:1
 cookie=0x0, duration=996.042s, table=0, n_packets=0, n_bytes=0, idle_age=996, ip,tcp,tun_id=0x1,tun_src=10.10.59.233,in_port=1 actions=resubmit(,1)
 cookie=0x0, duration=735.432s, table=0, n_packets=0, n_bytes=0, idle_age=735, ip,udp,tun_id=0x1,tun_src=10.10.59.233,in_port=1 actions=resubmit(,3)
 cookie=0x0, duration=38.611s, table=0, n_packets=17, n_bytes=1666, idle_age=4, ip,icmp,tun_id=0x1,tun_src=10.10.59.233,in_port=1,icmp_type=8,icmp_code=0 actions=drop
 cookie=0x0, duration=8564.271s, table=0, n_packets=68, n_bytes=5007, idle_age=19, priority=10,in_port=LOCAL actions=set_tunnel:0x1,load:0xa0a3be9->NXM_NX_TUN_IPV4_DST[],output:1
 cookie=0x0, duration=8478.707s, table=0, n_packets=40, n_bytes=2686, idle_age=19, priority=10,tun_id=0x1,tun_src=10.10.59.233,in_port=1 actions=LOCAL
 cookie=0x0, duration=2134.312s, table=1, n_packets=15, n_bytes=1110, idle_age=16, priority=0 actions=resubmit(,2)
 cookie=0x0, duration=217.208s, table=2, n_packets=0, n_bytes=0, idle_age=217, ip,tcp,tp_dst=2152 actions=LOCAL
 cookie=0x0, duration=5171.730s, table=3, n_packets=1, n_bytes=47, idle_age=4329, priority=0 actions=resubmit(,4)
 cookie=0x0, duration=185.586s, table=4, n_packets=0, n_bytes=0, idle_age=185, ip,udp,tp_dst=2152 actions=LOCAL


/////////////////////////
for one table all users
[root@10-10-28-238 ~]# ovs-ofctl dump-flows br0
NXST_FLOW reply (xid=0x4):
 cookie=0x0, duration=1017.569s, table=0, n_packets=1, n_bytes=74, idle_age=501, tcp,in_port=LOCAL,tcp_flags=+syn-ack actions=learn(table=1,idle_timeout=60,tun_id=0x1,tun_src=10.10.59.233,eth_type=0x800,nw_proto=6,NXM_OF_IP_SRC[]=NXM_OF_IP_DST[],NXM_OF_IP_DST[]=NXM_OF_IP_SRC[],NXM_OF_TCP_SRC[]=NXM_OF_TCP_DST[],NXM_OF_TCP_DST[]=NXM_OF_TCP_SRC[],output:NXM_OF_IN_PORT[]),set_tunnel:0x1,load:0xa0a3be9->NXM_NX_TUN_IPV4_DST[],output:1
 cookie=0x0, duration=1001.116s, table=0, n_packets=3, n_bytes=147, idle_age=129, udp,in_port=LOCAL actions=learn(table=3,idle_timeout=60,tun_id=0x1,tun_src=10.10.59.233,eth_type=0x800,nw_proto=17,NXM_OF_IP_SRC[]=NXM_OF_IP_DST[],NXM_OF_IP_DST[]=NXM_OF_IP_SRC[],NXM_OF_UDP_SRC[]=NXM_OF_UDP_DST[],NXM_OF_UDP_DST[]=NXM_OF_UDP_SRC[],output:NXM_OF_IN_PORT[]),set_tunnel:0x1,load:0xa0a3be9->NXM_NX_TUN_IPV4_DST[],output:1
 cookie=0x0, duration=938.928s, table=0, n_packets=20, n_bytes=1406, idle_age=252, tcp,in_port=1 actions=resubmit(,1)
 cookie=0x0, duration=932.274s, table=0, n_packets=5, n_bytes=243, idle_age=12, udp,in_port=1 actions=resubmit(,3)
 cookie=0x0, duration=909.626s, table=0, n_packets=63, n_bytes=6174, idle_age=556, icmp,tun_id=0x1,tun_src=10.10.59.233,in_port=1,icmp_type=8,icmp_code=0 actions=drop
 cookie=0x0, duration=874.946s, table=0, n_packets=32, n_bytes=1822, idle_age=7, priority=10,in_port=LOCAL actions=set_tunnel:0x1,load:0xa0a3be9->NXM_NX_TUN_IPV4_DST[],output:1
 cookie=0x0, duration=855.920s, table=0, n_packets=19, n_bytes=944, idle_age=7, priority=10,tun_id=0x1,tun_src=10.10.59.233,in_port=1 actions=LOCAL
 cookie=0x0, duration=802.350s, table=1, n_packets=13, n_bytes=936, idle_age=252, priority=0 actions=resubmit(,2)
 cookie=0x0, duration=698.223s, table=2, n_packets=8, n_bytes=566, idle_age=276, tcp,tun_id=0x1,tun_src=10.10.59.233,tp_dst=2152 actions=LOCAL
 cookie=0x0, duration=796.377s, table=3, n_packets=5, n_bytes=243, idle_age=12, priority=0 actions=resubmit(,4)
 cookie=0x0, duration=684.149s, table=4, n_packets=3, n_bytes=146, idle_age=67, udp,tun_id=0x1,tun_src=10.10.59.233,tp_dst=2152 actions=LOCAL


intel_iommu=on iommu=pt
gcc -Q -O0 --help=optimizers

# ovs-vsctl create qos type=linux-htb other-config:max-rate=900000000
69897202-385d-4b99-95b3-1523e86c6605
# ovs-vsctl create Queue other-config:min-rate=400000 other-config:max-rate=800000
2cad42af-fd6e-4e33-aa4e-8935dc452886
# ovs-vsctl add qos 69897202-385d-4b99-95b3-1523e86c6605 queues 0=2cad42af-fd6e-4e33-aa4e-8935dc452886
# ovs-vsctl set Port gre qos=69897202-385d-4b99-95b3-1523e86c660


//
tc qdisc add dev gre_sys root handle 1: htb default 10 r2q 10
tc class add dev gre_sys classid 1:1 root htb rate 100Mbit ceil 100Mbit burst 100Mbit cburst 100Mbit
tc class add dev gre_sys classid 1:2 root htb rate 200Mbit ceil 200Mbit burst 200Mbit cburst 200Mbit

in_port=LOCAL actions=set_queue:0,output:2
in_port=LOCAL actions=set_queue:1,output:2


/ovs

ofproto/ofproto.c: handle_openflow
lib/dpif-netdev.c: dpdk datapath
lib/dpif-netlink.c: kernel datapath netlink
ofproto/ofproto-dpif-xlate.c: userspace handle packet_in from datapath

需要在 package上级目录中创建一个 localversion的问题，该文件中写入 版本标识
make rpms/kernel
sources/kernel-4.14.0-x86_64.config


qemu build

192.168.150.31

docker run -it --rm -v `pwd`:/data mwdg/qemu-2.9-el7 /bin/bash
cd build
./make_rpm version_tag


rpm2cpio *.src.rpm | cpio -idmv

ip link add test type gre local 192.168.152.71 remote 192.168.152.72 nopmtudisc ignore-df



git clone https://github.com/cisco-system-traffic-generator/trex-core.git
# cd linux_dpdk
#./b configure  (only once)
#./b build

# cd ../scripts
# ./t-rex-64 --cfg /etc/trex_cfg.yaml  -i -c 8


./trex-console 
>>  start  -p 0 -f /root/uxr.py -m 1mpps

./configure -with-mlxfw-mod --with-ipoib-mod  --with-core-mod --with-user_mad-mod --with-user_access-mod --with-addr_trans-mod --with-mlx5-mod --with-iser-mod --with-isert-mod --with-srp-mod --with-nvmf_host-mod  --with-nvmf_target-mod --with-nfsrdma-mod -j 

mlxconfig -d /dev/mst/mt4119_pciconf0.1 set NUM_VF_MSIX=18 NUM_OF_VFS=28






kernel newbis:

IPv4: Currently adding a new ipv4 address always cause the creation of the related network route, with default metric. Add support for IFA_F_NOPREFIXROUTE for ipv4 address. When an address is added with such flag set, no associated network route is created, no network route is deleted when said IP is gone and it's up to the user space manage such route
ip a a 11.0.0.1/24 dev manbr noprefixroute

sysctl_ip_early_demux: local established tcp/udp skb bind with socket before route, so it can not lookup the route and the sock award, for only forward case should be disable 
bind sock and dst_cache(sk->sk_rx_dst)





crash:

crash /usr/lib/debug/lib/modules/kernelxx/vmlinuz vmcore

mod -s mlx5_core /usr/lib/debug/lib/modules/kernelxx/driver/net/ethernet/mellanox/mlx5/core/mlx5_core.ko.debug


llvm

https://github.com/llvm/llvm-project/releases/download/llvmorg-12.0.1/llvm-12.0.1.src.tar.xz
https://github.com/llvm/llvm-project/releases/download/llvmorg-12.0.1/clang-12.0.1.src.tar.xz
tar -xf clang-12.0.1.src.tar.xz
tar -xf llvm-12.0.1.src.tar.xz

mkdir clang-build
mkdir llvm-build

cd llvm-build
cmake3 -G "Unix Makefiles" -DLLVM_TARGETS_TO_BUILD="BPF;X86" \
  -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_RTTI=ON -DCMAKE_INSTALL_PREFIX=/usr ../llvm-12.0.1.src
make -j 32
make install

cd ../clang-build
cmake3 -G "Unix Makefiles" -DLLVM_TARGETS_TO_BUILD="BPF;X86" \
  -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/usr ../clang-12.0.1.src
make -j 32
make install


uninstall llvm/clang
cd xxx-build
xargs rm < install_manifest.txt


bcc:
git clone https://github.com/iovisor/bcc.git
cd bcc/
mkdir build; cd build
cmake3 .. -DCMAKE_INSTALL_PREFIX=/usr
make -j32
make install


bpftrace:
	
yum install centos-release-scl
yum install devtoolset-8
scl enable devtoolset-8 bash
git clone https://github.com/iovisor/bpftrace
cd bpftrace
mkdir build; cd build;
cmake3 -DCMAKE_BUILD_TYPE=Release ..
make -j32
make install


new gcc version
yum install centos-release-scl -y
yum install devtoolset-9 -y

scl enable devtoolset-9 bash  or  source /opt/rh/devtoolset-9/enable


make headers_install INSTALL_HDR_PATH=/usr

git send-email 00* --to pablo@netfilter.org --to fw@strlen.de --cc netfilter-devel@vger.kernel.org --cc netdev@vger.kernel.org


bf fw update
flint -d <mst device> -i FW.bin burn

cx5 fw update
mlxfwmanager -u -i fw-xxxx.bin


CPU:
pidstat: pid status, check cpu usage adn on which cpu
vmstat: show running process

perf record -a -g -F 997 [ -e event -p xxx ] sleep 10 
perf record -g -a -e context-switches -p 100 sleep 10
perf report  --stdio

perf sched record sleep 4
perf sched latency

perf stat -p 27224 sleep 2

perf top -a -g -p 27224  -U

perf list: list the event

MEMORY:
The result of the virtual memory model and demand allocation is that any page
of virtual memory may be in one of the following states:
A. Unallocated
B. Allocated, but unmapped (unpopulated and not yet faulted)
C. Allocated, and mapped to main memory (RAM)
D. Allocated, and mapped to the physical swap device (disk)

From these states, two memory usage terms can also be defined:
 Resident set size (RSS): the size of allocated main memory pages (C)
 Virtual memory size: the size of all allocated areas (B + C + D) 



Free list: a list of pages that are unused (also called idle memory) and 
available for immediate allocation. This is usually implemented as multiple free
page lists, one for each locality group (NUMA).

Page cache: the file system cache. A tunable parameter called swappiness
sets the degree to which to favor freeing memory from the page cache as
opposed to swapping.
 
Swapping: This is paging by the page-out daemon, kswapd, which finds 
notrecently-used pages to add to the free list, including application memory.
They are paged out, which may involve writing to either a file-system-based
swap file or a swap device. This is available only if a swap file or device has
been configured.

Reaping: When a low-memory threshold is crossed, kernel modules and the
kernel slab allocator can be instructed to immediately free any memory that
can easily be freed. This is also known as shrinking
 
OOM killer: The out-of-memory killer will free memory by finding and killing a
sacrificial process, found using select_bad_process() and then
killed by calling oom_kill_process(). This may be logged in the system log
(/var/log/messages) as an “Out of memory: Kill process” message.




Once free memory has reached the lowest threshold, kswapd operates in synchronous mode,
freeing pages of memory as they are requested (the kernel is
exempt from this requirement) [Gorman 04]. This lowest threshold is tunable
(vm.min_free_kbytes),


Page scanning: Look for continual page scanning (more than 10 s) as a sign of
memory pressure. On Linux, this can be done using sar -B and checking the
pgscan columns.
 
Paging: The paging of memory is a further indication that the system is low
on memory. On Linux, you can use vmstat(8) and check the si and so columns 
(here, the term swapping means anonymous paging).
 
vmstat: Run vmstat per second and check the free column for available
memory
vmstat -S m 1
vmstat -a 1

slabtop: kernel slab allocator statistics
slaptop -sc 1

Sar
 -B: paging statistics
 -H: huge pages statistics
 -r: memory utilization
 -R: memory statistics
 -S: swap space statistics
 -W: swapping statistics 

pmap: command lists the memory mappings of a process, showing their
sizes, permissions, and mapped objects
pmap -x 10252

vm.overcommit_memory 
0 = use a heuristic to allow reasonable overcommits; 1 = always overcommit; 
2 = don’t overcommit
vm.overcommit_ratio 















sonic:

YourPaSsWoRd

0,编译
make init && make configure PLATFORM=mellanox && make target/sonic-mellanox.bin

1,安装
sudo sonic_installer install /tmp/sonic-mellanox.bin

2，查看OS上目前运行的OS，以及新安装的OS
sudo sonic_installer list

3，重启
sudo reboot

4，查看运行的OS已经是新安装的OS了
sudo sonic_installer list

debug:

rm target/debs/stretch/swss_1.0.0_amd64.deb
make target/debs/stretch/swss_1.0.0_amd64.deb

docker cp swss_1.0.0_amd64.deb swss:/mnt
docker exec -ti swss bash
# dpkg -i /mnt/swss_1.0.0_amd64.deb

config reload



port init:
portsyncd:
1. read cfgdb PORT table to appdb PORT table and also store to g_portset. when finished, set PortConfigDone(attr is count of ports) to appdb in PORT table
2. linksyncd onmsg receive RTM_NEWLINK msg for "port" and set the "port" "state ok" in statedb for PORT table and del "port" fromg_portset
3. finnaly g_init not set and g_portset is empty which means all the port create successfully, and set PortInitDone to appdb in PORT table. set g_init

in the config_db
1. config :interface port相关
a. startup/shutdown: config--->portmgr--->portsorch 
for PORTCHANNEL, PORT, VLAN_SUB_INTERFACE table
config interface  startup/shutdown Ethernet0 
mod_entry("PORT", interface_name, {"admin_status": "up"})
mod_entry("PORT", interface_name, {"admin_status": "down"})

portmgr 
1). listen the PORT table in cfgdb and get the new chang port, check the port state is ok in statedb
2). set the key and attr to the "PORT_TABLE" table in appdb and "ip l set devport up/down"

b. mtu: config-->portconfig--->portmgr--->portsorch
for PORT table
config interface mtu Ethernet0 9000
mod_entry("PORT", interface_name, {"mtu": mtu})

portmgr 
1). listen the PORT table in cfgdb and get the new chang port, check the port state is ok in statedb
2). set the key and attr to the "PORT_TABLE" table in appdb and "ip l set dev port mtu xxxx"

3. speed： config-->portconfig---> buffermgr ---> portsorch
for PORT table
config interface speed Ethernet0 10000
mod_entry("PORT", interface_name, {"speed": speed})


all the ops handle the config_db in the portsyncd-->handlePortConfig: add this to app_db  why need this?


vlan:
2. config: vlan
a. add/del: config ---> vlanmgr ---> portsorch
for VLAN table
config vlan add/del vid
set_entry('VLAN', vlan, {'vlanid': vid})

vlanmgr
1). create host vlan interface and add key to m_vlans
2). add "admin_status", "mtu" attr to the "VLAN_TABLE" in appdb, set "state" ok for "VLAN_TABLE" in the statedb
3). for delete: remove host vlan interface and del key in m_vlans and del key in "VLAN_TABEL" appdb and statedb

b. member add/del: config ---> vlanmgr ---> portsorch
for VLAN_MEMBER table
config vlan member add/del Ethernet0
vlan['members'] = members
set_entry('VLAN', vlan_name, vlan)
set_entry('VLAN_MEMBER', (vlan_name, interface_name), {'tagging_mode': "untagged" if untagged else "tagged" })

vlanmgr
1). add host interface to vlan member (tagging_mode is only used in vlanmgr for host vlan member?)
2). the key(vlan100:ethernet0) to"VLAN_MEMBER_TABLE" in appdb, set "state" ok for "VLAN_MEMBER_TABLE" in the statedb
3). for delete: del host interface to vlan member, clear key "VLAN_MEMBER_TABLE" in appdb and in statedb




2. config :interface interface
a. ip add/remove : config --> intfmgr --> intfsorch
for VLAN_SUB_INTERFACE/INTERFACE/PORTCHANNEL_INTERFACE/VLAN_INTERFACE/LOOPBACK_INTERFACE/MGMT_INTERFACE table
config ip add/remove Ethernet0 1.1.1.1/24

config_db.set_entry(table_name, interface_name, {"NULL": "NULL"})  create interface_name entry in table
config_db.set_entry(table_name, (interface_name, ip_addr), {"NULL": "NULL"})  create interface_name:ip_addr in table

intfmgr
1). check portstate/vlan state table is ok , if it is a subvlan interface just create the vlan interface.
2). add the key and data to "INTF_TABLE" in the appdb, add the key to "INTERFACE_TABLE" in the statedb.
3). set address: check portstate/vlan state table is ok, check the interface_table in the statedb.
4). set host interface address, add name:address as key to "INTF_TABLE" in the appdb and the key to "INTERFACE_TABLE" in the statedb as state ok

a. vrf bind/unbind : config --> intfmgr --> intfsorch
for VLAN_SUB_INTERFACE/INTERFACE/PORTCHANNEL_INTERFACE/VLAN_INTERFACE/LOOPBACK_INTERFACE/MGMT_INTERFACE table
config vrf bind/ubind Ethernet1 Vrf100

config_db.set_entry(table_name, interface_name, None)
config_db.set_entry(table_name, interface_name, {"vrf_name": vrf_name})


intfmgr:
1). check portstate/vlan state table is ok , if it is a subvlan interface just create the vlan interface.
2). add the key and data to "INTF_TABLE" in the appdb, add the key to "INTERFACE_TABLE" in the statedb.
3). set vrf: check portstate/vlan state table is ok, check the interface_tatble in the statedb.
4). set host interface vrf, update vrf data in the key interf_name in "INTF_TABLE" within the appdb and update key to "INTERFACE_TABLE" in the statedb as state ok and vr_name



3. config route:
vtysh "ip r xxxx" ----> frr fpm --> fpmsyncd

The also get the route netlink from kernel to the fpmsyncd. 
But only the port in the "INTF_TABLE" and the nexthop is a nexthopentry(a validate neigbor)

So for case config ip add Ethernet0 1.1.1.1/24, it will add a link route 1.1.1.0/24 to th switch

fpmyncd:
add ip_prefix as key to "ROUTE_TABLE" in the appdb.


4. config vrf:
add/del: config-->vrfmgr-->vrforch
for VRF tabel
config vrf add/del Vrf100

config_db.set_entry('VRF', vrf_name, {"NULL": "NULL"})

vrfmgr
1). add key to "VRF_TABLE" in the appdb and also set the key in "VRF_TABLE" with statedb to "ok"
The "VRF_OBJECT_TABLE" in statedb used by the vrforch to check vrf is create in the hw



INTERFACE table里放的L3的port 不能成为vlan member, 配置ip address和bind vrf的interface都属于L3 interface 包括INTERFACE/VLAN_SUB_INTERFACE/PORTCHANNEL_INTERFACE/VLAN_INTERFACE/LOOPBACK_INTERFACE


bgp:


neighbor PGNAME peer-group
neighbor PEER peer-group PGNAME


ibgp传递给ebgp的ibgp路由会改为自己的下一跳
ibgp传递给ibgp的ebgp路由不会下一跳
neighbor PEER next-hop-self [all]: ibgp传递给ibgp的ebgp路由下一跳作为自己
neighbor PEER default-originate : 自己作为peer的默认网关
redistribute kernel : 内核三层路由推送给bgp
redistribute connected: 内核二层直连路由推送给bgp
redistribute static: frr 里配置的static路由推送给bgp
neighbor PEER remote-as external/internal

neighbor PEER update-source <IFNAME|ADDRESS>
neighbor PEER route-reflector-client

neighbor PEER ebgp-multihop 2
bgp disable-ebgp-connected-route-check: check ebgp不是直连 不是就不会发tcp syn


path selection:
neighbor PEER weight WEIGHT : value in local router / for inbound match

set local-preference  200 : vlaue in ibgp 比如路由传递通过rr 在ibgp中, ebgp获取的路由在ibg内传递 / for inbound match

neighbor 172.17.0.2 route-map PREF in
route-map PREF permit 10
  set local-preference 200

set as-path prepend AS-PATH
set as-path prepend last-as num

for inbound match:
 neighbor 172.17.0.4 route-map AP in
 route-map AP permit 10
   set as-path prepend 65003 65001
   set as-path prepend last-as 2

for outbound match:
 neighbor 172.17.0.1 route-map AP out
 route-map AP permit 10
   set as-path prepend 65003 65001
   set as-path prepend last-as 2   : last-as 就是最近一次的as tag 必须要有 不然network不能发布出去 , 比如从
igb内部发布给外面ebgp用这个就不行 因为as-path是空

set metric METRIC: for outbound 仅仅是单跳传递(可以i/ebgp), Where routes with a MED were received from the same AS, prefer the route with the lowest MED


Multi-path check

 If bgp bestpath as-path multipath-relax is set, all such routes are considered equal,
otherwise routes received via iBGP with identical AS_PATHs or routes received from eBGP neighbours in the same AS are considered equal.

bgp bestpath as-path multipath-relax

network network-number [route-map map-tag] 


neighbor 10.10.10.1 soft-reconfiguration inbound
clear bgp ipv4|ipv6 PEER soft|in|out




///////////////////////////////////////////////////////////////////////////



EBGP neighbors, by default, need to be directly connected: ebgp-multihop

Routes learned via IBGP are never propagated to other IBGP peers

The neighbor update-source command is normally used only with IBGP neighbors.
The address of an EBGP neighbor must be directly connected by default; the loopback of an EBGP neighbor is not directly connected























rdma-core-22.4-5.el7.x86_64
libibverbs-22.4-5.el7.x86_64
libibumad-22.4-5.el7.x86_64
ibacm-22.4-5.el7.x86_64
librdmacm-22.4-5.el7.x86_64
rdma-core-devel-22.4-5.el7.x86_64



echo 0 > tracing_on
echo nop > current_tracer

# 设置graph模式
echo function_graph > current_tracer
# 设置需要跟踪的函数
echo function_name > set_graph_function

# 开启跟踪
echo 1 > tracing_on
# 清空trace
> trace

# 查看函数跟踪信息
cat trace |less


# trace events
echo bpf_trace > /sys/kernel/debug/tracing/set_event







frr:
./configure     --bindir=/usr/bin     --sbindir=/usr/lib/frr     --sysconfdir=/etc/frr     --libdir=/usr/lib/frr     --libexecdir=/usr/lib/frr     --localstatedir=/var/run/frr     --with-moduledir=/usr/lib/frr/modules         --enable-multipath=64     --enable-user=frr     --enable-group=frr     --enable-vty-group=frrvty     --enable-systemd=yes     --disable-exampledir     --disable-ldpd     --enable-fpm     --with-pkg-git-version     --with-pkg-extra-version=-MyOwnFRRVersion     SPHINXBUILD=/usr/bin/sphinx-build

