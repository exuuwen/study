1. 当内核的port收到packet后会进入内核ovs收包函数

struct ovs_skb_cb {
	struct sw_flow		*flow; //报文所属的流表项
	struct sw_flow_key	*pkt_key;//报文的key
	struct ovs_key_ipv4_tunnel  *tun_key;//报文的tun key
	struct vport	*input_vport; //报文来至的vport
};
#define OVS_CB(skb) ((struct ovs_skb_cb *)(skb)->cb)

void ovs_vport_receive(struct vport *vport, struct sk_buff *skb,
		       struct ovs_key_ipv4_tunnel *tun_key)
{
	//从gre收到的报文才有tun_key
	OVS_CB(skb)->tun_key = tun_key;
	ovs_dp_process_received_packet(vport, skb);
}

void ovs_dp_process_received_packet(struct vport *p, struct sk_buff *skb)
{
	struct sw_flow_key key;
	//获取报文key, mark,vport_no,tunnel,l2, l3, l4的信息
	error = ovs_flow_extract(skb, p->port_no, &key);

	//处理报文
	ovs_dp_process_packet_with_key(skb, &key, false);	
	
}

void ovs_dp_process_packet_with_key(struct sk_buff *skb,
				    struct sw_flow_key *pkt_key,
				    bool recirc)
{
	/* Look up flow. */
	flow = ovs_flow_tbl_lookup_stats(&dp->table, pkt_key, skb_get_hash(skb),
					 &n_mask_hit);
	if (unlikely(!flow)) {
		struct dp_upcall_info upcall;
		//没有找到内核态流表项 就发送packet miss消息,key给vswitchd
		upcall.cmd = OVS_PACKET_CMD_MISS;
		upcall.key = pkt_key;
		upcall.portid = ovs_vport_find_upcall_portid(p, skb);
		ovs_dp_upcall(dp, skb, &upcall);
		consume_skb(skb);
		goto out;
	}

	OVS_CB(skb)->pkt_key = pkt_key;
	OVS_CB(skb)->flow = flow;

	//找到流表项 就执行其actions
	ovs_execute_actions(dp, skb, recirc);
}

int ovs_execute_actions(struct datapath *dp, struct sk_buff *skb, bool recirc)
{
	// tun_key只是给找flow用的
	OVS_CB(skb)->tun_key = NULL;
	//执行actions: modify fileld, push vlan, pop vlan, output
	error = do_execute_actions(dp, skb, acts->actions, acts->actions_len);
	//output:do_output-->ovs_vport_send(vport, skb);-->vport->ops->send(vport, skb);
}


2. 当内核没找到流表项的时候发送upcall给用户态

用户态有多个upcall handler线程接收upcall消息
void* udpif_upcall_handler(void *arg)
{
	//一次最多读取50个upcalls
	while (!latch_is_set(&handler->udpif->exit_latch)) {
		upcalls[FLOW_MISS_MAX_BATCH];
		n_upcalls = read_upcalls(handler, upcalls, miss_buf, &misses);
		if (!n_upcalls) {
            		//没有就等待
			dpif_recv_wait(udpif->dpif, handler->handler_id);
		}
		else {
			// 处理 upcalls
			handle_upcalls(handler, &misses, upcalls, n_upcalls);
		}
	}
}


struct upcall {
    struct flow_miss *flow_miss;    /* This upcall's flow_miss. */

    /* Raw upcall plus data for keeping track of the memory backing it. */
    struct dpif_upcall dpif_upcall; /* As returned by dpif_recv() */
    struct ofpbuf upcall_buf;       /* upcall消息报文 */
    uint64_t upcall_stub[512 / 8];  /* Buffer to reduce need for malloc(). */
};

struct dpif_upcall {
    /* All types. */
    enum dpif_upcall_type type;
    struct ofpbuf packet;       /* miss Packet data. */
    struct nlattr *key;         /* Flow key. */
    size_t key_len;             /* Length of 'key' in bytes. */

    /* DPIF_UC_ACTION only. */
    struct nlattr *userdata;    /* Argument to OVS_ACTION_ATTR_USERSPACE. */
};


a. read_upcalls
//从netlink读取upcall消息, 转换成dpif_upcall
dpif_recv-->dpif_linux_recv-->parse_odp_packet
{
	//upcall只有两种: packet miss 和 action to userspace
	type = (genl->cmd == OVS_PACKET_CMD_MISS ? DPIF_UC_MISS
            : genl->cmd == OVS_PACKET_CMD_ACTION ? DPIF_UC_ACTION
            : -1);
    	if (type < 0) {
        	return EINVAL;
    	}

    	/* (Re)set ALL fields of '*upcall' on successful return. */
    	upcall->type = type;
    	upcall->key = CONST_CAST(struct nlattr *,
                             nl_attr_get(a[OVS_PACKET_ATTR_KEY]));
    	upcall->key_len = nl_attr_get_size(a[OVS_PACKET_ATTR_KEY]);
    	upcall->userdata = a[OVS_PACKET_ATTR_USERDATA];

    	/* 初始化packet， 上传的miss数据包文*/
    	ofpbuf_use_stub(&upcall->packet,
                    CONST_CAST(struct nlattr *,
                               nl_attr_get(a[OVS_PACKET_ATTR_PACKET])) - 1,
                    nl_attr_get_size(a[OVS_PACKET_ATTR_PACKET]) +
                    sizeof(struct nlattr));
    	ofpbuf_set_data(&upcall->packet,
                    (char *)ofpbuf_data(&upcall->packet) + sizeof(struct nlattr));
    	ofpbuf_set_size(&upcall->packet, nl_attr_get_size(a[OVS_PACKET_ATTR_PACKET]));

    	*dp_ifindex = ovs_header->dp_ifindex;

}

//ovs并不把每个报文都当一个miss, 而是50个报文里面相同flow的报文当一个miss
static size_t
read_upcalls(struct handler *handler,
             struct upcall upcalls[FLOW_MISS_MAX_BATCH],
             struct flow_miss miss_buf[FLOW_MISS_MAX_BATCH],
             struct hmap *misses)
{
	for (i = 0; i < FLOW_MISS_MAX_BATCH; i++) {
        	struct upcall *upcall = &upcalls[n_upcalls];
        	struct flow_miss *miss = &miss_buf[n_misses];
		//初始化 upcall_buf: upcall传上来的数据报文
		ofpbuf_use_stub(&upcall->upcall_buf, upcall->upcall_stub,
                        sizeof upcall->upcall_stub);	
		//获取upcall信息, 包括dpif_upcall和buf
		error = dpif_recv(udpif->dpif, handler->handler_id,
                          &upcall->dpif_upcall, &upcall->upcall_buf);	
		
		dupcall = &upcall->dpif_upcall;
		packet = &dupcall->packet;
        
		/*把内核态flow转换成用户态度flow，根据dp_port， 获取ofproto(bridge操作符)*/
		error = xlate_receive(udpif->backer, packet, dupcall->key,
                              dupcall->key_len, &flow,
                              &ofproto, &ipfix, &sflow, NULL, &odp_in_port);
		
		//正常的话DPIF_UC_MISS,DPIF_UC_ACTION都转换为MISS_UPCALL
		type = classify_upcall(upcall);
        	if (type == MISS_UPCALL) {
			//从上传key(priorityi, mark,)和packet获取miss->flow
			flow_extract(packet, &md, &miss->flow);
			hash = flow_hash(&miss->flow, 0);
          		existing_miss = flow_miss_find(misses, ofproto, &miss->flow,
                                           hash);
      		//相同的流只用同一个miss表示
			if (!existing_miss) {
				// 初始化miss
                		hmap_insert(misses, &miss->hmap_node, hash);
                		miss->ofproto = ofproto;
                		miss->key = dupcall->key;
                		miss->key_len = dupcall->key_len;
                		miss->upcall_type = dupcall->type;
                		miss->odp_in_port = odp_in_port;
                		miss->put = false;
                		n_misses++;
            		} else {
                		miss = existing_miss;
            		}

            		upcall->flow_miss = miss;
            		n_upcalls++;
		}
	}
}


b. handle_upcalls
void xlate_actions(struct xlate_in *xin, struct xlate_out *xout)
{
	/*查找流表获取rule 如果没有查找到tables的属性的是controler那么返回一条action为controller的rule
	否则返回一条no_packet_in rule*/
	if (!xin->ofpacts && !ctx.rule) {
		ctx.table_id = rule_dpif_lookup(ctx.xbridge->ofproto, flow,
                                        !xin->skip_wildcards ? wc : NULL,
                                        &rule, ctx.xin->xcache != NULL);
		ctx.rule = rule;
    }

	//获取action
	actions = rule_dpif_get_actions(ctx.rule);
    	ofpacts = actions->ofpacts;

	/*根据rule的action转换为内核流表的action,放于ctx->xout->odp_actions
	 如果action是controller 那么会被标记为slow*/
	if (tnl_may_send && (!in_port || may_receive(in_port, &ctx))) {
            do_xlate_actions(ofpacts, ofpacts_len, &ctx);
}

/*处理upcall
1. 在tables里面去查找 到相应的flow
2. 转换flow为内核态度flow
2. 获取其action，对这条报文执行action
4. 向内核态下发flow
*/
void handle_upcalls(struct handler *handler, struct hmap *misses,
               struct upcall *upcalls, size_t n_upcalls)
{
	/*获取每个miss flow的actions*/
	HMAP_FOR_EACH (miss, hmap_node, misses) {
        	struct xlate_in xin;

        	xlate_in_init(&xin, miss->ofproto, &miss->flow, NULL,
                      miss->stats.tcp_flags, NULL);

        	xlate_actions(&xin, &miss->xout);
    	}	

	/*处理每个upcall*/
	for (i = 0; i < n_upcalls; i++) {
		/*获取upcall，相应的flow_miss, 以及packet*/
		struct upcall *upcall = &upcalls[i];
        struct flow_miss *miss = upcall->flow_miss;
        struct ofpbuf *packet = &upcall->dpif_upcall.packet;

		/*安装flow到内核, 同一miss flow的action flow只装一次, 并且只装DPIF_UC_MISS的flow*/
		/* Do not install a flow into the datapath if:
         *
         *    - The datapath already has too many flows.
         *
         *    - An earlier iteration of this loop already put the same flow.
         *
         *    - We received this packet via some flow installed in the kernel
         *      already. */
        if (may_put
            && !miss->put
            && upcall->dpif_upcall.type == DPIF_UC_MISS) {
			
			miss->put = true;
			/*创建一个ops向内核添加流表*/
			op = &ops[n_ops++];
            op->type = DPIF_OP_FLOW_PUT;
            op->u.flow_put.flags = DPIF_FP_CREATE;
            op->u.flow_put.key = miss->key;
            op->u.flow_put.mask = ofpbuf_data(&mask);
		
			/*获取下发flow的action
			slow表示在tables没有找到流表 就下发一条action usersapce的内核流表*/
			if (!miss->xout.slow) {
                op->u.flow_put.actions = ofpbuf_data(&miss->xout.odp_actions);
                op->u.flow_put.actions_len = ofpbuf_size(&miss->xout.odp_actions);
            } else {
                struct ofpbuf buf;

                compose_slow_path(udpif, &miss->xout, &miss->flow,
                                  miss->odp_in_port, &buf);
                op->u.flow_put.actions = ofpbuf_data(&buf);
                op->u.flow_put.actions_len = ofpbuf_size(&buf);
            }
	
		/*对于非slow path, 对于upcall的报文根据action产生一个packet out*/	
		if (ofpbuf_size(&miss->xout.odp_actions)) {
            	op = &ops[n_ops++];
            	op->type = DPIF_OP_EXECUTE;
            	op->u.execute.packet = packet;
            	odp_key_to_pkt_metadata(miss->key, miss->key_len,
                                    &op->u.execute.md);
            	op->u.execute.actions = ofpbuf_data(&miss->xout.odp_actions);
        	}	
	    }
	}

	//执行每个ops
	dpif_operate(udpif->dpif, opsp, n_ops);
}
