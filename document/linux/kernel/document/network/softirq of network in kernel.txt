

1. recieve
when packet is handled in the driver, it will be deliverd to softirq
example:
a.  retrieve a buffer from the ring 
   skb = fetch_rx_buffer(rx_ring, rx_desc);
b. set skb->hash and checksum, skb->queue_mapping(multiple queue case)
   rx_hash(rx_ring, rx_desc, skb);
   rx_checksum(rx_ring, rx_desc, skb);
   skb_record_rx_queue(skb, rx_ring->queue_index);
c. get the L2  
   skb->protocol = eth_type_trans(skb, dev);

d. deliver to softirq 
int net_dev_init()
{
	/*allocate sd for each cpu*/
	for_each_possible_cpu(i) {
		struct softnet_data *sd = &per_cpu(softnet_data, i);

		/*init the input and process queues*/
		skb_queue_head_init(&sd->input_pkt_queue);
		skb_queue_head_init(&sd->process_queue);
		INIT_LIST_HEAD(&sd->poll_list);
		/*set the output queue*/
		sd->output_queue_tailp = &sd->output_queue;
#ifdef CONFIG_RPS
		sd->csd.func = rps_trigger_softirq;
		sd->csd.info = sd;
		sd->cpu = i;
#endif
		/*backlog poll*/
		sd->backlog.poll = process_backlog;
		/*
		cat /proc/sys/net/core/dev_weight 
		64
		*/
		sd->backlog.weight = weight_p;
	}

	open_softirq(NET_TX_SOFTIRQ, net_tx_action);
	open_softirq(NET_RX_SOFTIRQ, net_rx_action);
}

/*schedule backlog poll to rx_action*/
static inline void ____napi_schedule(struct softnet_data *sd,
				     struct napi_struct *napi)
{
	list_add_tail(&napi->poll_list, &sd->poll_list);
	__raise_softirq_irqoff(NET_RX_SOFTIRQ);
}

把报文deliver到当前cpu的软中断上，所以把该irq分配到所有的cpu上，其软中断也几乎平分到所有的cpu上
netif_rx-->netif_rx_internal--> enqueue_to_backlog(skb, get_cpu(), &qtail);
{
	sd = &per_cpu(softnet_data, cpu);

	qlen = skb_queue_len(&sd->input_pkt_queue);
	/*
	# cat /proc/sys/net/core/netdev_max_backlog 
	1000
	*/

	if (qlen <= netdev_max_backlog )
	{
		if (skb_queue_len(&sd->input_pkt_queue)) {
enqueue:
			__skb_queue_tail(&sd->input_pkt_queue, skb);
			input_queue_tail_incr_save(sd, qtail);
			
			return NET_RX_SUCCESS;
		}

		/* Schedule NAPI for backlog device
		 * We can use non atomic operation since we own the queue lock
		 */
		if (!__test_and_set_bit(NAPI_STATE_SCHED, &sd->backlog.state)) {
			/*start backlog process*/
			____napi_schedule(sd, &sd->backlog);
		}
		goto enqueue;
	}
	}
	
	sd->dropped++;
	kfree_skb(skb);
}


static void net_rx_action(struct softirq_action *h)
{
	struct softnet_data *sd = &__get_cpu_var(softnet_data);
	unsigned long time_limit = jiffies + 2;
	int budget = netdev_budget;
	
	while (!list_empty(&sd->poll_list)) 
	{	
		/*budget and timeout*/
		/*
		cat /proc/sys/net/core/netdev_budget 
		300
		*/
		/*一次软中断最多2s和最多处理300个报文, 下次softirq再来处理*/
		if (unlikely(budget <= 0 || time_after_eq(jiffies, time_limit)))
			goto softnet_break;

		/*get poll list*/
		n = list_first_entry(&sd->poll_list, struct napi_struct, poll_list);
		weight = n->weight;
		if (test_bit(NAPI_STATE_SCHED, &n->state)) {
			/*返回0表示处理完全，在poll中会做napi_complete*/
			work = n->poll(n, weight);
		}

		budget -= work;

		/*表示没处理完*/		
		if (unlikely(work == weight)) 
		{
			if (unlikely(napi_disable_pending(n)))
			{
				/*del the napi from the poll list, clear the napi flag NAPI_STATE_SCHED*/
				napi_complete(n);
			}
			else
			{
				/*加到sd->poll_list尾*/
				list_move_tail(&n->poll_list, &sd->poll_list);
			}
		}
	}

softnet_break:
	sd->time_squeeze++;
	__raise_softirq_irqoff(NET_RX_SOFTIRQ);
}

int process_backlog(struct napi_struct *napi, int quota)
{
	while (1) {
		struct sk_buff *skb;

		while ((skb = __skb_dequeue(&sd->process_queue))) {
			local_irq_enable();
			/*dequeue to netif_recieve_skb*/
			__netif_receive_skb(skb);
			local_irq_disable();
			/*一次backlog最多处理64个报文*/
			if (++work >= quota) {
				local_irq_enable();
				return work;
			}
		}

		if (skb_queue_empty(&sd->input_pkt_queue)) {
			/*no backlog clear the napi and del it from the poll list*/
			list_del(&napi->poll_list);
			napi->state = 0;

			break;
		}
		
		//append the input_pkt_queue to process queue
		skb_queue_splice_tail_init(&sd->input_pkt_queue, &sd->process_queue);
	}
}

2. send
dev_queue_xmit-->__dev_queue_xmit
{
	/*chosee the txq*/
	txq = netdev_pick_tx(dev, skb, accel_priv);
	/*add to the tc qdisc*/
	if (q->enqueue) {
		rc = __dev_xmit_skb(skb, q, dev, txq);
		goto out;
	}

	/*if no tc qdisc, sned it dirctly*/
	if (dev->flags & IFF_UP) {
		rc = dev_hard_start_xmit(skb, dev, txq);
	}
}

struct netdev_queue *netdev_pick_tx(struct net_device *dev,
				    struct sk_buff *skb,
				    void *accel_priv)
{
	/*get the txqueue*/
	if (dev->real_num_tx_queues != 1) {
		const struct net_device_ops *ops = dev->netdev_ops;
		if (ops->ndo_select_queue)
			queue_index = ops->ndo_select_queue(dev, skb, accel_priv,
							    __netdev_pick_tx);
		else
			/*hash it*/
			queue_index = __netdev_pick_tx(dev, skb);
	}

	skb_set_queue_mapping(skb, queue_index);
	return netdev_get_tx_queue(dev, queue_index);
}

int __dev_xmit_skb()
{
	if ((q->flags & TCQ_F_CAN_BYPASS) && !qdisc_qlen(q) &&
		   qdisc_run_begin(q)) {
		/*如果qdisc能够BYPASS，qdisc len为空，qdisc没有run就直接发送报文，如果后面还有报文就进行qdisc run发送*/
		if (sch_direct_xmit(skb, q, dev, txq, root_lock)) {
			__qdisc_run(q);
		} else
			qdisc_run_end(q);

		rc = NET_XMIT_SUCCESS;
	}
	else {
		/*其他就直接enqeueu*/
		rc = q->enqueue(skb, q) & NET_XMIT_MASK;
		/*qdisc没有run的时候（比如qdisc为空不能bypass，设置为running，就行disc run发送*/
		if (qdisc_run_begin(q)) {
			__qdisc_run(q);
		}
	}
	
}

void __qdisc_run(struct Qdisc *q)
{
	int quota = weight_p;

	/*qdisc_restart: 从qdisc dequeue下skb 发送出去*/
	while (qdisc_restart(q)) {
		/*当一次发送300个或者需要被调度的时候，queue还没发送完，就把qdisc加入softirq的output_queue, 让软中断去发送*/
		if (--quota <= 0 || need_resched()) {
			__netif_schedule(q);
			break;
		}
	}

	qdisc_run_end(q);
}


static inline void __netif_schedule
{
	if (!test_and_set_bit(__QDISC_STATE_SCHED, &q->state))
	{
		/*把qdisc加入softirq queue， 唤起softirq*/
		sd = &__get_cpu_var(softnet_data);
		q->next_sched = NULL;
		*sd->output_queue_tailp = q;
		sd->output_queue_tailp = &q->next_sched;
		raise_softirq_irqoff(NET_TX_SOFTIRQ);
	}
}

/*deqeue from qdisc in the tx softirq*/
void net_tx_action(struct softirq_action *h)
{
	if (sd->output_queue) {
		struct Qdisc *head;

		local_irq_disable();
		head = sd->output_queue;
		sd->output_queue = NULL;
		sd->output_queue_tailp = &sd->output_queue;

		while (head) {
			struct Qdisc *q = head;
			head = head->next_sched;				
			clear_bit(__QDISC_STATE_SCHED, &q->state);
			/*dequeue from qdisc adn send it*/
			qdisc_run(q);
		}
	}
}






 


